{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e54c44a7-6e5a-4ee0-80bd-09868d04a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7155c3-27de-4387-8604-3a822caac461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62cda621-961f-45b6-95b8-09a8c4c76300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello-Hello', ',', '-', 'I', 'am', 'Ganapathy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "E_TEXT = \"Hello-Hello , - I am Ganapathy\"\n",
    "a= word_tokenize(E_TEXT)\n",
    "#type(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab25adb5-7352-41a5-b381-3c2829e9efd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive thinking!', 'You know is all.', 'A matter of habits If you are?', 'not quite a positive thinker Change Yourself?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "#ispace , a=[,.?,!]\n",
    "S2_TEXT = \"Positive thinking! You know is all. A matter of habits If you are? not quite a positive thinker Change Yourself?\"\n",
    "print(sent_tokenize(S2_TEXT))\n",
    "## type(sent_tokenize(E_TEXT)) ##!,? and."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a213e2f9-128e-4536-aabf-231632547123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Do you know Customer and target audience’s reviews can be analyzed?', 'You can  use this!', 'to create a roadmap of features and products.']\n"
     ]
    }
   ],
   "source": [
    "### Convert below para into word token and sentence token\n",
    "eg_text = 'Do you know Customer and target audience’s reviews can be analyzed? You can  use this! to create a roadmap of features and products.'\n",
    "print(sent_tokenize(eg_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d85cc1-a656-4177-b015-8def4d8c5c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'think', 'i', 'that', 'Learning', 'DATA', 'Science', 'will', 'bring', 'a', 'big', 'leap', 'in', 'your', 'Carrier', 'Profile', '.', 'Data', 'science', 'is', 'an', 'interdisciplinary', 'field', 'that', 'uses', 'scientific', 'methods', ',', 'processes', ',', 'algorithms', 'and', 'systems', 'to', 'extract', 'knowledge', 'and', 'insights', 'from', 'noisy', ',', 'structured', 'and', 'unstructured', 'data', ',', 'and', 'apply', 'knowledge', 'from', 'data', 'across', 'a', 'broad', 'range', 'of', 'application', 'domains']\n",
      "Lenghth of words =  58\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "a = \"I think i that Learning  DATA Science will bring a big leap in your Carrier Profile. Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge from data across a broad range of application domains\"\n",
    "word_tokens = word_tokenize(a)\n",
    "print(word_tokens)\n",
    "print (\"Lenghth of words = \",len(word_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd36043b-e70c-4290-ab78-75d87eed0a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'think', 'Learning', 'DATA', 'Science', 'bring', 'big', 'leap', 'Carrier', 'Profile', '.', 'Data', 'science', 'interdisciplinary', 'field', 'uses', 'scientific', 'methods', ',', 'processes', ',', 'algorithms', 'systems', 'extract', 'knowledge', 'insights', 'noisy', ',', 'structured', 'unstructured', 'data', ',', 'apply', 'knowledge', 'data', 'across', 'broad', 'range', 'application', 'domains']\n",
      "The number of words stopped : 18\n",
      "Lenghth of words =  40\n"
     ]
    }
   ],
   "source": [
    "stop_words1 = set(stopwords.words('english')) #downloads the file with english stop words\n",
    "word_tokens = word_tokenize(a)\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words1]\n",
    "print(filtered_sentence)\n",
    "#print(word_tokens)\n",
    "#print(filtered_sentence)\n",
    "print(\"The number of words stopped :\",(len(word_tokens)-len(filtered_sentence)))\n",
    "print (\"Lenghth of words = \",len(filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad57009-7dc1-4948-90dd-ebf5fa83e49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['think', 'Learning', 'DATA', 'Science', 'bring', 'big', 'leap', 'Carrier', 'Profile', 'Data', 'science', 'interdisciplinary', 'field', 'uses', 'scientific', 'methods', 'processes', 'algorithms', 'systems', 'extract', 'knowledge', 'insights', 'noisy', 'structured', 'unstructured', 'data', 'apply', 'knowledge', 'data', 'across', 'broad', 'range', 'application', 'domains']\n",
      "The number of words stopped : 24\n",
      "Lenghth of words filtered sentence =  34\n"
     ]
    }
   ],
   "source": [
    "b=[\"I\",\".\",\",\",\",\",\"?\",\":\"]  #Creating your own Stop word list\n",
    "stop_words1=list(stop_words1)\n",
    "stop_words2 = b #downloads the file with english stop words\n",
    "stop_words=stop_words1+stop_words2\n",
    "word_tokens = word_tokenize(a)\n",
    " \n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "print(filtered_sentence)\n",
    " \n",
    "#print(word_tokens)\n",
    "#print(filtered_sentence)\n",
    "print(\"The number of words stopped :\",(len(word_tokens)-len(filtered_sentence)))\n",
    "print (\"Lenghth of words filtered sentence = \",len(filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99cf6850-a21f-4ca1-aca1-9443fa513874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aim\n",
      "aim\n",
      "aim\n",
      "aimmer\n",
      "aim\n",
      "aim\n",
      "call\n",
      "caller\n",
      "call\n",
      "call\n",
      "call\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    " \n",
    "ps = PorterStemmer() ## defining stemmer\n",
    "s_words = [\"Aims\",\"Aims\",\"Aimed\",\"Aimmer\",\"Aiming\",\"Aim\",\"Calls\",\"Caller\",\"Calling\",\"Call\",\"Called\"]\n",
    "for i in s_words:\n",
    "    print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7116951f-d7b4-4005-8988-6fb6ad59906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_words = [\"Dance\", \"dances\", \"Dancing\", \"dancer\", \"dances\", \"danced\", \"Goods\",\"Good\",\"sings\",\"singings\",\"that\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3e720a-4b24-46e2-93ef-72746c5abdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Whether', 'IN'), ('you', 'PRP'), (\"'re\", 'VBP'), ('new', 'JJ'), ('to', 'TO'), ('DataScience', 'NNP'), ('or', 'CC'), ('an', 'DT'), ('paracetamol', 'NN'), (',', ','), ('it', 'PRP'), (\"'s\", 'VBZ'), ('easy', 'JJ'), ('to', 'TO'), ('learn', 'VB'), ('and', 'CC'), ('use', 'VB'), ('Python.Are', 'NNP'), ('you', 'PRP'), ('Good', 'NNP'), ('enough', 'RB'), ('in', 'IN'), ('Prgramming', 'NNP'), ('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "document = 'Whether you\\'re new to DataScience or an paracetamol , it\\'s easy to learn and use Python.Are you Good enough in Prgramming?'\n",
    "\n",
    "sentences = nltk.sent_tokenize(document)   \n",
    "\n",
    "for sent in sentences: \n",
    "    print(nltk.pos_tag(nltk.word_tokenize(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95f73359-8fb0-456e-bd3d-00a66e1d109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion.n.01\n",
      "emotion\n",
      "any strong feeling\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "# Then, we're going to use the term \"D\" to find synsets like so:\n",
    "syns = wordnet.synsets(\"Emotion\")\n",
    "# An example of a synset:\n",
    "print(syns[0].name())\n",
    "# Just the word:\n",
    "print(syns[0].lemmas()[0].name())\n",
    "# Definition of that first synset:\n",
    "print(syns[0].definition())\n",
    "# Examples of the word in use in sentences:\n",
    "print(syns[0].examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "386bf906-1778-4935-97a7-5eb01efd3510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words = {'sound', 'vocalise', 'phone', 'well-grounded', 'heavy', 'voice', 'legal', 'go', 'intelligent', 'fathom', 'healthy', 'level-headed', 'audio', 'vocalize', 'auditory_sensation', 'reasoned', 'effectual', 'good', 'wakeless', 'strait', 'profound', 'levelheaded', 'speech_sound'}\n",
      "{'unsound', 'silence', 'devoice'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "for syn in wordnet.synsets(\"Sound\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(\"Similar words =\",set(synonyms))\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f688d21-ceeb-4472-98fa-4d145edd4ee0",
   "metadata": {},
   "source": [
    "## Lab Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e44d7f2-b1c4-4820-9e60-bdbd7d16dcae",
   "metadata": {},
   "source": [
    "Create a Script which can accept a text and Ask users of following after word token. \n",
    "1. Use Stop Words \n",
    "2. Part-Of-Speech tagging\n",
    "3. Generate antonyms and opposite words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc553af2-b13e-4cb7-b2f8-2bd428a013f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cecc7b63-f32a-4026-b328-5b7145228106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your text here: I dont LYK this, at all. Please SToP!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i dont lyk this, at all. please stop!\n"
     ]
    }
   ],
   "source": [
    "text = str(input('Please enter your text here:')).lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "360c1fb2-cb9d-4f60-ac40-79042384c9ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'dont', 'lyk', 'this', 'at', 'all', 'please', 'stop']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization of text\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "text_words = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "text_sc = list(re.sub(r'[a-zA-Z0-9 ]', '', text))\n",
    "word_tokens = word_tokenize(text_words)\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "babd7738-119e-4fcc-823c-f2173b64d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words():\n",
    "    print('\\nYou have chosen \"Stop words\"\\n')       \n",
    "    from nltk.corpus import stopwords\n",
    "    import re\n",
    "    global filtered_sentence\n",
    "    global stop_words_list\n",
    "    stop_words1 = set(stopwords.words('english')) #downloads the file with english stop words\n",
    "    filtered_sentence = set([w for w in word_tokens if not w in stop_words1])\n",
    "    stop_words_list = [w for w in word_tokens if w in stop_words1]\n",
    "    for ele in text_sc:\n",
    "        stop_words_list.append(ele)\n",
    "    stop_words_list = set(stop_words_list)\n",
    "    print('Original text: ', text)\n",
    "    print(\"Filtered sentence:\", filtered_sentence)\n",
    "    print(\"Stop words:\", stop_words_list)\n",
    "    print(\"The number of words stopped:\", (len(word_tokens) + len(text_sc) - len(filtered_sentence)))\n",
    "    print(\"Lenghth of filtered sentence:\", len(filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0226a1e-1b3f-485a-92b6-780878982e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging():\n",
    "    print('\\nYou have chosen \"Part-Of-Speech tagging\"\\n')\n",
    "    from nltk import pos_tag\n",
    "    print(pos_tag(word_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "032d839d-b8c4-4a7f-a666-bd772ee45a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antonyms():\n",
    "    global filtered_sentence\n",
    "    global stop_words_list\n",
    "    print('\\nYou have chosen \"antonyms/opposite words\"\\n')\n",
    "    print('Filtered sentence:', filtered_sentence)\n",
    "    while True:\n",
    "        antonym_opt3_text = str(input('Please enter the word for which you want to find antonyms:')).lower()\n",
    "        if antonym_opt3_text in word_tokens:\n",
    "            from nltk.corpus import wordnet\n",
    "            antonyms = []\n",
    "            for syn in wordnet.synsets(antonym_opt3_text):\n",
    "                for l in syn.lemmas():\n",
    "                    # print(l.antonyms())\n",
    "                    if l.antonyms():\n",
    "                        antonyms.append(l.antonyms()[0].name())\n",
    "            print('Antonyms/opposite words: ', set(antonyms))\n",
    "            break\n",
    "        else:\n",
    "            print('Please enter a word present in the original text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc96753c-f45e-4ffc-8fa2-80945ad1f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_program():\n",
    "    print('Thank you!')\n",
    "    # quit()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67c6e8c-558b-4cf8-a956-d4900432f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incorrect_option():\n",
    "    print('Incorrect option')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e52d396-0206-4c02-a579-ffdb7a4cc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def continue_program():\n",
    "#     contYN = str(input('Continue? [Y/N]')).upper()\n",
    "#     if contYN == 'Y':\n",
    "#         main_func()\n",
    "#     elif contYN == 'N':\n",
    "#         break\n",
    "#     else:\n",
    "#         print('Please choose Y/N')\n",
    "#         continue_program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5614057-969d-47b6-90df-f623b9ed2fd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main_func():\n",
    "    while True:\n",
    "        options_number = int(input('\\n1. Use Stop Words \\n2. Part-Of-Speech tagging\\n3. Generate antonyms and opposite words.\\\n",
    "        \\n4. Exit\\nPlease select your option:'))\n",
    "        if options_number == 1:\n",
    "            stop_words()\n",
    "        elif options_number == 2:\n",
    "            pos_tagging()\n",
    "        elif options_number == 3:\n",
    "            antonyms()\n",
    "        elif options_number == 4:\n",
    "            exit_program()\n",
    "            break\n",
    "        else:\n",
    "            incorrect_option()\n",
    "        # continue_program()\n",
    "        # contYN = str(input('Continue? [Y/N]')).upper()\n",
    "        # if contYN == 'Y':\n",
    "        #     continue\n",
    "        # elif contYN == 'N':\n",
    "        #     break\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2ac3afa-5273-4383-aec9-126c5bbe6814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Use Stop Words \n",
      "2. Part-Of-Speech tagging\n",
      "3. Generate antonyms and opposite words.        \n",
      "4. Exit\n",
      "Please select your option: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect option\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Use Stop Words \n",
      "2. Part-Of-Speech tagging\n",
      "3. Generate antonyms and opposite words.        \n",
      "4. Exit\n",
      "Please select your option: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have chosen \"Stop words\"\n",
      "\n",
      "Original text:  i dont lyk this, at all. please stop!\n",
      "Filtered sentence: {'dont', 'stop', 'lyk', 'please'}\n",
      "Stop words: {',', 'this', '.', 'all', 'i', 'at', '!'}\n",
      "The number of words stopped: 7\n",
      "Lenghth of filtered sentence: 4\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Use Stop Words \n",
      "2. Part-Of-Speech tagging\n",
      "3. Generate antonyms and opposite words.        \n",
      "4. Exit\n",
      "Please select your option: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have chosen \"Part-Of-Speech tagging\"\n",
      "\n",
      "[('i', 'NN'), ('dont', 'VBP'), ('lyk', 'NN'), ('this', 'DT'), ('at', 'IN'), ('all', 'DT'), ('please', 'NN'), ('stop', 'VB')]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Use Stop Words \n",
      "2. Part-Of-Speech tagging\n",
      "3. Generate antonyms and opposite words.        \n",
      "4. Exit\n",
      "Please select your option: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect option\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Use Stop Words \n",
      "2. Part-Of-Speech tagging\n",
      "3. Generate antonyms and opposite words.        \n",
      "4. Exit\n",
      "Please select your option: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have chosen \"antonyms/opposite words\"\n",
      "\n",
      "Filtered sentence: {'dont', 'stop', 'lyk', 'please'}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the word for which you want to find antonyms: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a word present in the original text\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the word for which you want to find antonyms: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antonyms/opposite words:  {'begin', 'continuant_consonant', 'continue', 'start'}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Use Stop Words \n",
      "2. Part-Of-Speech tagging\n",
      "3. Generate antonyms and opposite words.        \n",
      "4. Exit\n",
      "Please select your option: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you!\n"
     ]
    }
   ],
   "source": [
    "main_func()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57e3e183-aa54-48cb-8be2-98aea2d45b05",
   "metadata": {},
   "source": [
    "# Doubts\n",
    "1) How to deal with periods in stop words? (Remove them manually or any library inside NLTK to treat them?)\n",
    "2) antonyms() function had a LOT of blank values, why so?\n",
    "3) Indexing of antonyms() but nothing like that for synset()?\n",
    "\n",
    "Issues: \n",
    "1) Variable <filtered_sentence> created in UDF 1 are used in UDF 3 but throws error since UDF 3 is outside scope of UDF 1 (SOLVED: Use global variable (or) pass variables as parameters)\n",
    "2) Why am I pressing exit twice? (SOLVED: Don't call main function inside a UDF, you will have to close it twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca90f5bc-945c-4184-8faf-b4e7ad04f744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
