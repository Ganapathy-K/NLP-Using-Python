{
 "cells": [
  {
   "cell_type": "raw",
   "id": "61ffff59-afc2-4818-8c9f-106252e6adc0",
   "metadata": {},
   "source": [
    "Input Text: \"Ashi is happy to work in Gurgoan. Work brings happiness to Ashi.\"\n",
    "\"Happy people work better in Gurgoan. Ashi enjoys the work culture here.\"\n",
    "\"The work environment in her company makes Ashi very happy.\"\n",
    "\"Happiness comes from working hard and work life balance\"\n",
    " \n",
    "Lab Questions:\n",
    "    Apply Count Vectorization to the provided text data and answer the following:\n",
    "        Display the Count Vectorizer Matrix.\n",
    "        Display the Vocabulary.\n",
    "        Identify the term with the highest frequency.\n",
    "        Which term(s) occur in all sentences?\n",
    "        Explain how the frequency of the word 'happy' changes across the sentences.\n",
    "        What would happen if we set stop_words= 'english' in the CountVectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce15876-4679-4220-9c72-363abd6f3505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.36 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ffad3d-b08a-4a30-83af-5718140c25e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ashi is happy to work in Gurgoan. Work brings happiness to Ashi.', 'Happy people work better in Gurgoan. Ashi enjoys the work culture here.', 'The work environment in her company makes Ashi very happy.', 'Happiness comes from working hard and work life balance.']\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"Ashi is happy to work in Gurgoan. Work brings happiness to Ashi.\", \n",
    "    \"Happy people work better in Gurgoan. Ashi enjoys the work culture here.\", \n",
    "    \"The work environment in her company makes Ashi very happy.\", \n",
    "    \"Happiness comes from working hard and work life balance.\"\n",
    "]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec018071-e867-49fe-a711-5e297c0cbb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ashi is happy to work in Gurgoan Work brings happiness to Ashi', 'Happy people work better in Gurgoan Ashi enjoys the work culture here', 'The work environment in her company makes Ashi very happy', 'Happiness comes from working hard and work life balance']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "corpus_an = []\n",
    "for text in corpus:\n",
    "    corpus_an.append(re.sub(r'[^a-zA-Z0-9 ]', '', text)) # Pick only alpha numeric characters from text\n",
    "print(corpus_an)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f4b2161-3872-4ff4-94ac-f3fdb2de3a5d",
   "metadata": {},
   "source": [
    "Display the Count Vectorizer Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2093364-6a64-4236-9a38-932b566395b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.48 s\n",
      "Wall time: 19.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer() # Using CountVectorizer\n",
    "X_count = count_vectorizer.fit_transform(corpus_an)\n",
    "type(X_count)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f3dd1a5-3b96-4658-885e-60521c357034",
   "metadata": {},
   "source": [
    "Display the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d82e90b3-7d86-4492-91ef-47422fd806f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "['and' 'ashi' 'balance' 'better' 'brings' 'comes' 'company' 'culture'\n",
      " 'enjoys' 'environment' 'from' 'gurgoan' 'happiness' 'happy' 'hard' 'her'\n",
      " 'here' 'in' 'is' 'life' 'makes' 'people' 'the' 'to' 'very' 'work'\n",
      " 'working']\n",
      "\n",
      "Count Vectorizer Matrix:\n",
      "[[0 2 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 2 0 2 0]\n",
      " [0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 2 0]\n",
      " [0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0]\n",
      " [1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary:\")\n",
    "print(count_vectorizer.get_feature_names_out()) # Print 'vocabulary' (unique words in the corpus, in ascending order)\n",
    "print()\n",
    "print(\"Count Vectorizer Matrix:\")\n",
    "print(X_count.toarray())  # Convert the sparse matrix to array for better visibility"
   ]
  },
  {
   "cell_type": "raw",
   "id": "082fd48a-24ba-48ad-84e1-a2fe727f939b",
   "metadata": {},
   "source": [
    "Identify the term with the highest frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9b50d8-a6f2-4504-a31e-d94bc572f313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ashi is happy to work in gurgoan work brings happiness to ashi happy people work better in gurgoan ashi enjoys the work culture here the work environment in her company makes ashi very happy happiness comes from working hard and work life balance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_combined = ' '.join(corpus_an).lower() # Combining each document/row into a single string\n",
    "corpus_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59060919-4fc7-49ee-b6d5-b6183c1fb807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Distribution: [('work', 6)]\n",
      "CPU times: total: 1.03 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "freq_dist = FreqDist(corpus_combined.split()) # Calculating most frequent words \n",
    "print(\"Frequency Distribution:\", freq_dist.most_common(1)) # Term with the highest frequency"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e2cef8d-347c-44f5-99a3-5e75af0052b0",
   "metadata": {},
   "source": [
    "Which term(s) occur in all sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbfa6b2f-0ae8-478e-9060-d04b87f74ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 2 0 2 0]\n",
      "[0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 2 0]\n",
      "[0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0]\n",
      "[1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "for i in X_count.toarray():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27b204e2-7eac-49d0-81f1-97fc27858207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term \"work\" occurs in all sentences\n"
     ]
    }
   ],
   "source": [
    "X_count_array_transposed = X_count.toarray().transpose() # Transposing the X_count array\n",
    "product_list = []\n",
    "for i in range(len(X_count_array_transposed)): # Nested for-loop to calculate product row wise (column-wise in X_count array)\n",
    "    product = 1\n",
    "    for j in X_count_array_transposed[i]:\n",
    "        product *= j\n",
    "    product_list.append(product) # Appending final product to a list\n",
    "\n",
    "for i, j in enumerate(product_list): # If product is not null => the term appears in ALL documents\n",
    "    if j != 0:\n",
    "        print('The term \"%s\" occurs in all sentences' % count_vectorizer.get_feature_names_out()[i])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08c0ab5c-9338-490f-9c12-d5d903cd355a",
   "metadata": {},
   "source": [
    "Explain how the frequency of the word 'happy' changes across the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb536a72-73ae-479e-91b3-fe967a9b71e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'ashi', 'balance', 'better', 'brings', 'comes', 'company',\n",
       "       'culture', 'enjoys', 'environment', 'from', 'gurgoan', 'happiness',\n",
       "       'happy', 'hard', 'her', 'here', 'in', 'is', 'life', 'makes',\n",
       "       'people', 'the', 'to', 'very', 'work', 'working'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60514182-1661-4c7d-ae59-f566fd56456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Ashi is happy to work in Gurgoan. Work brings happiness to Ashi.\n",
      "1 Happy people work better in Gurgoan. Ashi enjoys the work culture here.\n",
      "2 The work environment in her company makes Ashi very happy.\n",
      "3 Happiness comes from working hard and work life balance.\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer() ## defining stemmer\n",
    "feature_names_stemmed = []\n",
    "\n",
    "for idx, document in enumerate(corpus):\n",
    "    print(idx, document)\n",
    "#     print(ps.stem(document.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28721390-72e0-426e-9506-465fadbf1c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "4f40359d-e6e1-41ee-9276-cc50c2d216c3",
   "metadata": {},
   "source": [
    "What would happen if we set stop_words='english' in the CountVectorizer?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19986f48-1b2d-486d-9536-83c07e04b7cf",
   "metadata": {},
   "source": [
    "Shoud we manually explain the tone of 'happy' or should we write a code (Like for pick out term that occurs in all documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc05af1-169f-4f89-b911-4883317d92f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
